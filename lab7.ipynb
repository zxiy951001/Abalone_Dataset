{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 7\n",
    "#### Name: Yeo Zheng Xu Isaac UOWID: 6342425"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset from local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset (4177, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:/Users/Isaac Yeo/Downloads/abalone.data',sep=',',header= None)\n",
    "print(\"shape of dataset\",dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data by adding Column names and encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Dismeer</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Dismeer  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455    0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350    0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530    0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440    0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330    0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=['Sex','Length','Dismeer','Height','Whole weight','Shucked weight',\n",
    "              'Viscera weight','Shell weight','Rings']\n",
    "dataset.columns=column_names\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Dismeer</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Dismeer  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.455    0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350    0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530    0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440    0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330    0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  Sex_F  Sex_I  Sex_M  \n",
       "0         0.150     15      0      0      1  \n",
       "1         0.070      7      0      0      1  \n",
       "2         0.210      9      1      0      0  \n",
       "3         0.155     10      0      0      1  \n",
       "4         0.055      7      0      1      0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset = pd.get_dummies(dataset,columns=['Sex'])\n",
    "encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 train set and 3 test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 7/10 train set and  3/10 test set\n",
    "train_set=encoded_dataset.sample(frac=0.7,random_state=49)\n",
    "test_set=encoded_dataset.drop(train_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2924, 10)\n",
      "(2924, 1)\n",
      "(1253, 10)\n",
      "(1253, 1)\n"
     ]
    }
   ],
   "source": [
    "#Target variable in Ring column \n",
    "#Generate train data and train labels\n",
    "x_train = train_set.drop('Rings',axis=1)\n",
    "x_train.reset_index(inplace=True,drop=True)\n",
    "y_train = train_set['Rings']\n",
    "\n",
    "#Generate test data and test labels\n",
    "x_test = test_set.drop('Rings',axis=1)\n",
    "x_train.reset_index(inplace=True,drop=True)\n",
    "y_test = test_set['Rings']\n",
    "\n",
    "#Set correct dimension tensorflow \n",
    "y_train = np.expand_dims(y_train,axis=1)\n",
    "y_test = np.expand_dims(y_test,axis=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function for batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(x,y,batch_size=64):\n",
    "    #shuffle first\n",
    "    x =x.sample(frac=1)\n",
    "    y =y[x.index]\n",
    "    num_batches = len(x) // batch_size\n",
    "    batches=[]\n",
    "    for i in range(num_batches):\n",
    "        start_index = batch_size * i\n",
    "        end_index = start_index + batch_size\n",
    "        batches.append((\n",
    "            x.iloc[start_index: end_index, :],\n",
    "            y[start_index:end_index]     \n",
    "        ))\n",
    "     \n",
    "    #leftover data\n",
    "    if(num_batches * batch_size <len(x)):\n",
    "        start_index = num_batches * batch_size\n",
    "        batches.append((\n",
    "            x.iloc[start_index:,:],\n",
    "            y[start_index:]  \n",
    "        ))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = encoded_dataset.shape[1] - 1\n",
    "n_neurons_1st = 64 # number of neurons in frist hidden layer\n",
    "n_neurons_2nd = 64 # number of neurons in second hideen layer\n",
    "n_neurons_out = 1  # output layer has 1 neuron (regression problem)\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#placeholders,x=data y_true = target\n",
    "x = tf.placeholder(tf.float32,shape=[None,n_features],name=\"x\")\n",
    "y_true =tf.placeholder(tf.float32,shape=[None,n_neurons_out],name=\"y\")\n",
    "\n",
    "#variables\n",
    "#first hideen layer weights and bias\n",
    "w_1st = tf.get_variable(\"weights_1st\",\n",
    "                        dtype=tf.float32,\n",
    "                        shape=[n_features,n_neurons_1st],\n",
    "                        initializer=tf.glorot_uniform_initializer())\n",
    "\n",
    "b_1st = tf.get_variable(\"bias_1st\",\n",
    "                        dtype=tf.float32,\n",
    "                        shape=[1,n_neurons_1st],\n",
    "                        initializer= tf.zeros_initializer())\n",
    "\n",
    "w_2nd = tf.get_variable(\"weights_2nd\",\n",
    "                        dtype=tf.float32,\n",
    "                        shape=[n_neurons_1st,n_neurons_2nd],\n",
    "                        initializer=tf.glorot_uniform_initializer())\n",
    "\n",
    "b_2nd = tf.get_variable(\"bias_2nd\",\n",
    "                        dtype=tf.float32,\n",
    "                        shape=[1,n_neurons_2nd],\n",
    "                        initializer= tf.zeros_initializer())\n",
    "\n",
    "w_out = tf.get_variable(\"weights_out\",\n",
    "                        dtype=tf.float32,\n",
    "                        shape=[n_neurons_2nd,n_neurons_out],\n",
    "                        initializer=tf.glorot_uniform_initializer())\n",
    "\n",
    "b_out = tf.get_variable(\"bias_out\",\n",
    "                        dtype=tf.float32,\n",
    "                        shape=[1,n_neurons_out],\n",
    "                        initializer= tf.zeros_initializer())\n",
    "\n",
    "#compute output of each layer\n",
    "x_1st = tf.matmul(x,w_1st)+ b_1st\n",
    "x_1st = tf.nn.relu(x_1st)#output 1st layer\n",
    "\n",
    "x_2nd = tf.matmul(x_1st,w_2nd)+ b_2nd\n",
    "x_2nd = tf.nn.relu(x_2nd)#output 2md layer\n",
    "\n",
    "x_out = tf.matmul(x_2nd,w_out)+ b_out #final layer output\n",
    "y_hat = x_out\n",
    "\n",
    "#L2 regularization term\n",
    "l2_lambda = 0.001 #lambda coefficient\n",
    "l2_reg = (l2_lambda * tf.nn.l2_loss(w_1st)+l2_lambda * tf.nn.l2_loss(w_2nd)\n",
    "          + l2_lambda * tf.nn.l2_loss(w_out))\n",
    "\n",
    "#optimization(MSE) with l2 regualarization\n",
    "cost = tf.losses.mean_squared_error(y_true,y_hat)+ l2_reg\n",
    "learning_rate =0.01 #learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)#gradient descent optimizer\n",
    "training_op = optimizer.minimize(cost)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training cost: 7.0647607\n",
      "Epoch 10 training cost: 7.6836667\n",
      "Epoch 20 training cost: 5.336216\n",
      "Epoch 30 training cost: 5.0658083\n",
      "Epoch 40 training cost: 5.074678\n",
      "Epoch 50 training cost: 5.1944776\n",
      "Epoch 60 training cost: 7.1789274\n",
      "Epoch 70 training cost: 4.640029\n",
      "Epoch 80 training cost: 4.7236104\n",
      "Epoch 90 training cost: 5.561826\n",
      "Epoch 100 training cost: 4.494275\n",
      "Epoch 110 training cost: 4.6226497\n",
      "Epoch 120 training cost: 4.4736934\n",
      "Epoch 130 training cost: 4.4664564\n",
      "Epoch 140 training cost: 4.47509\n",
      "Epoch 150 training cost: 4.4797983\n",
      "Epoch 160 training cost: 4.6541133\n",
      "Epoch 170 training cost: 4.5808387\n",
      "Epoch 180 training cost: 4.6826215\n",
      "Epoch 190 training cost: 4.434239\n",
      "Epoch 200 training cost: 5.861637\n",
      "Epoch 210 training cost: 4.4010854\n",
      "Epoch 220 training cost: 4.3763075\n",
      "Epoch 230 training cost: 4.4984837\n",
      "Epoch 240 training cost: 4.4400992\n",
      "Epoch 250 training cost: 4.5635295\n",
      "Epoch 260 training cost: 4.6314626\n",
      "Epoch 270 training cost: 4.7157216\n",
      "Epoch 280 training cost: 4.392329\n",
      "Epoch 290 training cost: 4.365957\n",
      "Epoch 300 training cost: 4.3747897\n",
      "Epoch 310 training cost: 4.354889\n",
      "Epoch 320 training cost: 4.747701\n",
      "Epoch 330 training cost: 4.427187\n",
      "Epoch 340 training cost: 4.355788\n",
      "Epoch 350 training cost: 4.9809375\n",
      "Epoch 360 training cost: 4.4220366\n",
      "Epoch 370 training cost: 4.3739285\n",
      "Epoch 380 training cost: 4.3673058\n",
      "Epoch 390 training cost: 4.946102\n",
      "Epoch 400 training cost: 4.4780426\n",
      "Epoch 410 training cost: 4.373232\n",
      "Epoch 420 training cost: 4.4390693\n",
      "Epoch 430 training cost: 4.303337\n",
      "Epoch 440 training cost: 4.3100567\n",
      "Epoch 450 training cost: 4.397085\n",
      "Epoch 460 training cost: 4.361586\n",
      "Epoch 470 training cost: 4.688975\n",
      "Epoch 480 training cost: 5.390245\n",
      "Epoch 490 training cost: 4.667224\n",
      "training MSE: 4.476651\n",
      "Test MSE 4.301572\n"
     ]
    }
   ],
   "source": [
    "# execution the model\n",
    "init =tf.global_variables_initializer()\n",
    "n_epochs =500\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        batches = generate_batches(x_train, y_train, batch_size = 64)\n",
    "        for batch in batches:\n",
    "            x_train_batch = batch[0]\n",
    "            y_train_batch = batch[1]\n",
    "            sess.run(training_op,feed_dict={x: x_train_batch, y_true:y_train_batch})\n",
    "        #print training cost every 10 epochs\n",
    "        if epoch %10 ==0:\n",
    "            training_cost = sess.run(cost,feed_dict={x:x_train,y_true:y_train})\n",
    "            print(\"Epoch\",epoch,\"training cost:\",training_cost)\n",
    "    print(\"training MSE:\",sess.run(cost,feed_dict={x:x_train,y_true:y_train}))    \n",
    "    test_cost = sess.run(cost,feed_dict={x:x_test,y_true:y_test})\n",
    "    print(\"Test MSE\", test_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "#### - First Layer (input layer) have 10 neurons which is equal to the number of features. Train set+ Test set = 10.\n",
    "#### - Hidden Layer 1 have 64 neurons. Relu(Rectified Linear Unit) activation function is use on its output.  \n",
    "#### - Hidden Layer 2 have 64 neurons. Relu(Rectified Linear Unit) activation function is use on its output.  \n",
    "#### - Output Layer have 1 neuron as it is regression problem. No activation function use \n",
    "#### - Regularization we apply L2 regularization for both hidden layer and output layer. Coefficient is 0.001.(Task Requirement 8)\n",
    "#### - Learning rate = 0.01\n",
    "#### - Optimizer =GradientDescentOptimizer (Task Requirement 2) \n",
    "#### - Cost Function is mean square error. (Task requirement 7)\n",
    "#### - Epoch = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  * The best MSE on test set achived is around 4.++. There is no overfitting too because the train MSE and test MSE is around the same value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - We will use Keras as an altemative implementation here. The same architecture and parameters used in Tensorflow implementation will be used here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - We use the same parameters so that we can compare with TensorFlow implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers,regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253/1253 [==============================] - 0s 68us/sample - loss: 4.2422\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "n_nodes =64 #number of nodes in each hidden layer\n",
    "l2_lambda = 0.001 #l2 regularization coefficient\n",
    "\n",
    "model.add(Dense(n_nodes,activation='relu',\n",
    "kernel_regularizer=regularizers.l2(l2_lambda),input_dim = n_features))\n",
    "model.add(Dense(n_nodes,activation='relu',\n",
    "kernel_regularizer=regularizers.l2(l2_lambda)))\n",
    "model.add(Dense(1,kernel_regularizer=regularizers.l2(l2_lambda)))\n",
    "\n",
    "n_epochs = 500 #number  of epochs\n",
    "learning_rate = 0.01 # learning rate\n",
    "batch_size =64 #batch size\n",
    "\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate),loss='mse')\n",
    "history = model.fit(x_train,y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=n_epochs,\n",
    "                   validation_split = 0.2,\n",
    "                   verbose=False)\n",
    "score = model.evaluate(x_test,y_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2924/2924 [==============================] - 0s 52us/sample - loss: 4.4189\n",
      "keras train MSE: 4.4189409890024836\n",
      "keras test MSE: 4.242174203930525\n"
     ]
    }
   ],
   "source": [
    "print(\"keras train MSE:\",model.evaluate(x_train,y_train,batch_size=128))\n",
    "print(\"keras test MSE:\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The result with Keras implementation is quite similar with Tensorflow implementation result MSE is around 4.++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
